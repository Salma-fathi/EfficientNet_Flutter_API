{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c42458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from typing import Dict, Union\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "# Map class names to the model's output index\n",
    "CLASS2IDX = {\"Fake\": 0, \"Real\": 1}\n",
    "# Map the model's output index back to a class name\n",
    "IDX2CLASS = {v: k for k, v in CLASS2IDX.items()}\n",
    "\n",
    "# --------------------------\n",
    "# Model Definition\n",
    "# --------------------------\n",
    "def create_model(num_classes: int = 2) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Creates an EfficientNet-V2 Small model with a custom classifier head.\n",
    "    \"\"\"\n",
    "    model = efficientnet_v2_s()\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# --------------------------\n",
    "# Preprocessing (Transform)\n",
    "# --------------------------\n",
    "class ResizePadToSquare:\n",
    "    \"\"\"\n",
    "    A custom transform to resize an image to a square, preserving aspect ratio\n",
    "    by scaling the longer side to `size` and padding the shorter side.\n",
    "    \"\"\"\n",
    "    def __init__(self, size: int, fill: int = 0, interpolation = Image.BICUBIC):\n",
    "        self.size = size\n",
    "        self.fill = fill\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img: Image.Image) -> Image.Image:\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "        w, h = img.size\n",
    "        scale = self.size / max(w, h)\n",
    "        new_w, new_h = max(1, int(round(w * scale))), max(1, int(round(h * scale)))\n",
    "        img = img.resize((new_w, new_h), self.interpolation)\n",
    "        \n",
    "        pad_w = self.size - new_w\n",
    "        pad_h = self.size - new_h\n",
    "        left = pad_w // 2\n",
    "        top = pad_h // 2\n",
    "        right = pad_w - left\n",
    "        bottom = pad_h - top\n",
    "        \n",
    "        img = ImageOps.expand(img, border=(left, top, right, bottom), fill=self.fill)\n",
    "        return img\n",
    "\n",
    "def get_inference_transform(img_size: int) -> transforms.Compose:\n",
    "    \"\"\"\n",
    "    Returns the complete preprocessing pipeline for inference.\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        ResizePadToSquare(img_size, fill=0, interpolation=Image.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# --------------------------\n",
    "# Inference Class (Single Model)\n",
    "# --------------------------\n",
    "\n",
    "class ImagePredictor:\n",
    "    \"\"\"\n",
    "    A class to load a single model and run inference on images.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 ckpt_path: str, \n",
    "                 device: str = \"cuda\", \n",
    "                 img_size: int = 384):\n",
    "        \"\"\"\n",
    "        Initializes the predictor.\n",
    "        \n",
    "        Args:\n",
    "            ckpt_path: The file path to the .pt or .pth model checkpoint.\n",
    "            device: The device to run inference on (e.g., \"cuda\" or \"cpu\").\n",
    "            img_size: The square size the image will be resized/padded to.\n",
    "        \"\"\"\n",
    "        self.device = torch.device(device)\n",
    "        self.img_size = img_size\n",
    "        self.transform = get_inference_transform(self.img_size)\n",
    "        \n",
    "        # Load the single model\n",
    "        print(f\"Loading model from {ckpt_path} onto {self.device}...\")\n",
    "        self.model = self._load_model(ckpt_path)\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "    def _load_model(self, ckpt_path: str) -> nn.Module:\n",
    "        \"\"\"Private helper to load the model from its checkpoint.\"\"\"\n",
    "        num_classes = len(CLASS2IDX)\n",
    "        \n",
    "        if not Path(ckpt_path).exists():\n",
    "            raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "            \n",
    "        model = create_model(num_classes)\n",
    "        try:\n",
    "            # Load state dict from the checkpoint file\n",
    "            # Assumes checkpoint is saved as {\"model\": state_dict, ...}\n",
    "            sd = torch.load(ckpt_path, map_location=self.device)[\"model\"]\n",
    "            model.load_state_dict(sd)\n",
    "            model.to(self.device)\n",
    "            model.eval()  # Set model to evaluation mode\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint {ckpt_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, image_path: str) -> Dict[str, Union[str, int, float]]:\n",
    "        \"\"\"\n",
    "        Runs inference on a single image from a file path.\n",
    "        \n",
    "        Args:\n",
    "            image_path: The file path to the image.\n",
    "            \n",
    "        Returns:\n",
    "            A dictionary containing the prediction and probabilities.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 1. Open and convert image\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {image_path}: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "        # 2. Preprocess the image\n",
    "        tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # 3. Run inference\n",
    "        with torch.cuda.amp.autocast(enabled=(self.device.type == \"cuda\")):\n",
    "            logits = self.model(tensor)\n",
    "            # Calculate probabilities\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        # 4. Get probabilities for each class\n",
    "        prob_fake = probs[0, CLASS2IDX[\"Fake\"]].item()\n",
    "        prob_real = probs[0, CLASS2IDX[\"Real\"]].item()\n",
    "        \n",
    "        # 5. Determine final prediction\n",
    "        pred_idx = torch.argmax(probs, dim=1).item()\n",
    "        pred_label = IDX2CLASS[pred_idx]\n",
    "        \n",
    "        # 6. Format the output\n",
    "        return {\n",
    "            \"predicted_label\": pred_label,\n",
    "            \"predicted_index\": pred_idx,\n",
    "            \"probabilities\": {\n",
    "                \"Fake\": prob_fake,\n",
    "                \"Real\": prob_real\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "CHECKPOINT_FILE = \"bankk_runs_effv2s/your_model_checkpoint.pt\"  # <--- CHANGE THIS\n",
    "TEST_IMAGE = \"imgs/my_test_image.jpg\"                  # <--- CHANGE THIS\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Create a dummy image for testing if it doesn't exist ---\n",
    "img_path = Path(TEST_IMAGE)\n",
    "if not img_path.exists():\n",
    "    print(f\"Creating dummy test image at: {img_path}\")\n",
    "    img_path.parent.mkdir(exist_ok=True)\n",
    "    Image.new('RGB', (500, 500), color = 'red').save(img_path)\n",
    "\n",
    "# --- Initialize the predictor ---\n",
    "# This loads the model onto the GPU (or CPU)\n",
    "try:\n",
    "    predictor = ImagePredictor(\n",
    "        ckpt_path=CHECKPOINT_FILE,\n",
    "        device=DEVICE,\n",
    "        img_size=384  # Adjust if your model was trained on a different size\n",
    "    )\n",
    "    print(\"\\nPredictor is ready.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n--- ERROR ---\")\n",
    "    print(f\"Could not find model file: {e}\")\n",
    "    print(\"Please update CHECKPOINT_FILE to the correct path.\")\n",
    "    predictor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f598f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictor:\n",
    "    # --- Run prediction on your image ---\n",
    "    print(f\"Running prediction on: {TEST_IMAGE}\")\n",
    "    result = predictor.predict(TEST_IMAGE)\n",
    "    \n",
    "    # --- Print the result ---\n",
    "    print(\"\\n--- Prediction Result ---\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "else:\n",
    "    print(\"Predictor was not initialized. Please fix the checkpoint path in Cell 2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
